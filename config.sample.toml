# Sample of a configuration. Copy this file and edit it. Set the environment variable `AMP_CONFIG`
# to its location. See the CONFIG.md for more context.
# 
# Note that using a config file is not mandatory. You can alternatively provide some or all values
# through env vars. See the 'Using env vars' section of CONFIG.md for how to do this.
#
# When using filesystem paths, any relative paths will be resolved from the directory of this file.

# Where the extracted datasets are stored.
data_dir = "<config_dir/data>"

# Path to a providers directory. Each provider is configured as a separate toml file in this
# directory. Dataset definitions will reference providers by a relative path to this directory.
providers_dir = "<config_dir/providers>"

# Path to a directory containing dataset definition files.
dataset_defs_dir = "<config_dir/dataset_defs>"

# Connection to the metadata DB. Optional. If not set, a temporary postgres DB will be provided.
# To opt out of this default behavior, set `ALLOW_TEMP_DB` to `false` in the environment.
# By default, temporary DBs will be created and persisted in the OS temp directory.
metadata_db_url = "postgres://<pg_url>"

# Metadata DB configuration (optional)
# [metadata_db]
# Database connection URL - alternative to metadata_db_url above
# url = "postgres://<pg_url>"

# Size of the connection pool (default: 10)
# pool_size = 10

# How much memory the server can use in MB. Setting this to 0, the default, means unlimited.
# max_mem_mb = 0

# Paths where DataFusion can create temporary files, enabling spill-to-disk when aggregation or join
# state exceeds the memory limit.
#
# spill_location = []

# Service addresses (optional - defaults shown below)
# Arrow Flight RPC server address
# flight_addr = "0.0.0.0:1602"

# JSON Lines server address  
# jsonl_addr = "0.0.0.0:1603"

# Admin API server address
# admin_api_addr = "0.0.0.0:1610"

# Writer/Parquet configuration (renamed from [parquet] to [writer], optional)
# [writer]
# Compression algorithm: zstd, lz4, gzip, brotli, snappy, uncompressed (default: zstd(1))
# compression = "zstd(1)"

# Enable bloom filters (default: false)
# bloom_filters = false

# Parquet metadata cache size in MB (default: 1024)
# cache_size_mb = 1024

# Target partition size configuration
# Overflow is a tuning parameter that provides some flexibility for some cases,
# e.g. if two files that are both slightly larger than 50% of the size limit won't
# compact because their total exceeds the limit. Overflow provides some flexibility
# in this case. Additionally, the segment size algorithm is based on an approximation
# of the future compacted segment size which might end up being smaller or larger
# depending on factors like table width, value cardinality, compression ratios, etc.
# So adjusting Overflow provides a mechanism to reflect the realities of the data
# at rest while configuring the compaction algorithm.
# Examples:
# overflow = "1"      # 1x target size (default)
# overflow = "1.5"    # 1.5x target size

# Target bytes per file - 2GB (default: 2147483648 or 2GB)
# Note: nozzle dump commpand may optionally override this if a partition_size_mb is provided
# or if the NOZZLE_PARTITION_SIZE_MB env var is set.
# bytes = 2147483648

# Target rows per file, 0 means no limit (default: 0)
# rows = 0

# File compactor configuration (nested under writerl, optional)
# [writer.compactor]
# Enable or disable the compactor (default: false)
# active = false

# The maximum number of concurrent metadata operations (default: 2)
# metadata_concurrency = 2

# The maximum number of concurrent compaction write operations (default: 2)
# write_concurrency = 2

# The interval at which to run the compactor (default: 1 second)
# min_interval = 1

# Compaction algorithm configuration
# cooldown_duration = 5  # Base cooldown duration in seconds (default: 5 seconds)

# Eager compaction limits (when to compact eagerly)
# overflow = 1 # Overflow configuration (default: 1)
# blocks = 0  # Block threshold for eager compaction (default: 0)
# bytes = 0  # Byte threshold for eager compaction (default: 0)
# rows = 0  # Row threshold for eager compaction (default: 0)

# Garbage collector configuration (nested under writer, optional)
# [writer.collector]
# Enable or disable the collector (default: false)
# active = false

# The interval at which to run the garbage collector (default: 5 seconds)
# [writer.collector.min_interval]
# secs = 5

# The duration for which to hold a deletion lock on compacted files (default: 30 minutes, minimum: 200 milliseconds)
# [writer.collector.deletion_lock_duration]
# secs = 1800
