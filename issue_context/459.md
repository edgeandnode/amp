# Move input_batch_size_blocks into StreamingQuery

Microbatch size control can be a StreamingQuery responsibility. Steps:

1. Add a test for input_batch_size_blocks
2. Refactor it into StreamingQuery
3. Rename to microbatch_max_interval or something

# 1. Add a test for input_batch_size_blocks

## Objective
Test that `input_batch_size_blocks` parameter controls Parquet file granularity during SQL dataset dumps.

## How it was fixed
Created test using `sql_stream_ds.even_blocks` that dumps data on-the-spot rather than restoring blessed data. Test validates that `input_batch_size_blocks=1` creates 4 files for 4 blocks, including empty files when SQL filter produces no results.

## Considerations for future work
- Parameter controls file creation at block level even when queries return no data
- Empty file generation behavior must be preserved during refactoring
- On-the-spot dumping approach removes dependency on blessed data availability
